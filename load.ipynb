{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b055668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import mediapipe as mp\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "# Suppress TensorFlow warnings\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = \"3\"\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_pose = mp.solutions.pose\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba81a84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExerciseRecognizer:\n",
    "    def __init__(self, model_path, actions, sequence_length=30, confidence_threshold=0.5):\n",
    "        \"\"\"\n",
    "        Initialize the Exercise Recognition system\n",
    "        \n",
    "        Args:\n",
    "            model_path: Path to the trained .h5 model file\n",
    "            actions: List of exercise action names (must match training order)\n",
    "            sequence_length: Number of frames to analyze (must match training)\n",
    "            confidence_threshold: Minimum confidence to classify an action\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        self.actions = np.array(actions)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.threshold = confidence_threshold\n",
    "        \n",
    "        # Load the trained model\n",
    "        print(f\"Loading model from: {model_path}\")\n",
    "        self.model = tf.keras.models.load_model(model_path)\n",
    "        print(\"Model loaded successfully!\")\n",
    "        \n",
    "        # Initialize tracking variables\n",
    "        self.sequence = []\n",
    "        self.predictions = []\n",
    "        self.current_action = ''\n",
    "        self.current_confidence = 0.0\n",
    "        \n",
    "        # Initialize rep counters\n",
    "        self.reset_counters()\n",
    "        \n",
    "        # Colors for visualization\n",
    "        self.colors = [(245,117,16), (117,245,16), (16,117,245), (200,100,200), (100,200,100)]\n",
    "        while len(self.colors) < len(self.actions):\n",
    "            self.colors.append((np.random.randint(0,255), np.random.randint(0,255), np.random.randint(0,255)))\n",
    "    \n",
    "    def reset_counters(self):\n",
    "        \"\"\"Reset all exercise counters\"\"\"\n",
    "        self.curl_counter = 0\n",
    "        self.squat_counter = 0\n",
    "        self.plank_counter = 0\n",
    "        self.pushup_counter = 0\n",
    "        \n",
    "        self.curl_stage = None\n",
    "        self.squat_stage = None\n",
    "        self.plank_stage = None\n",
    "        self.pushup_stage = None\n",
    "        \n",
    "        self.plank_start_time = 0\n",
    "        self.last_plank_end = 0\n",
    "    \n",
    "    def mediapipe_detection(self, image, model):\n",
    "        \"\"\"Detect pose landmarks using MediaPipe\"\"\"\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = model.process(image)\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        return image, results\n",
    "    \n",
    "    def draw_landmarks(self, image, results):\n",
    "        \"\"\"Draw pose landmarks on the image\"\"\"\n",
    "        if results.pose_landmarks:\n",
    "            mp_drawing.draw_landmarks(\n",
    "                image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "            )\n",
    "    \n",
    "    def extract_keypoints(self, results):\n",
    "        \"\"\"Extract keypoints from MediaPipe results\"\"\"\n",
    "        if results.pose_landmarks:\n",
    "            pose = np.array([[res.x, res.y, res.z, res.visibility] \n",
    "                           for res in results.pose_landmarks.landmark]).flatten()\n",
    "        else:\n",
    "            pose = np.zeros(33*4)\n",
    "        return pose\n",
    "    \n",
    "    def calculate_angle(self, a, b, c):\n",
    "        \"\"\"Calculate angle between three points\"\"\"\n",
    "        a = np.array(a)\n",
    "        b = np.array(b)\n",
    "        c = np.array(c)\n",
    "        \n",
    "        radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "        angle = np.abs(radians*180.0/np.pi)\n",
    "        \n",
    "        if angle > 180.0:\n",
    "            angle = 360 - angle\n",
    "            \n",
    "        return angle\n",
    "    \n",
    "    def get_coordinates(self, landmarks, side, joint):\n",
    "        \"\"\"Get x,y coordinates of a specific joint\"\"\"\n",
    "        coord = getattr(mp_pose.PoseLandmark, f\"{side.upper()}_{joint.upper()}\")\n",
    "        x_coord = landmarks[coord.value].x\n",
    "        y_coord = landmarks[coord.value].y\n",
    "        return [x_coord, y_coord]\n",
    "    \n",
    "    def viz_joint_angle(self, image, angle, joint):\n",
    "        \"\"\"Display joint angle on the image\"\"\"\n",
    "        height, width = image.shape[:2]\n",
    "        cv2.putText(image, str(int(angle)), \n",
    "                   tuple(np.multiply(joint, [width, height]).astype(int)), \n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    def count_reps(self, image, current_action, landmarks):\n",
    "        \"\"\"\n",
    "        Count repetitions based on the recognized action and pose landmarks\n",
    "        Improved logic to better match model predictions\n",
    "        \"\"\"\n",
    "        if not landmarks:\n",
    "            return\n",
    "            \n",
    "        try:\n",
    "            # Only count reps if we have high confidence in the action\n",
    "            if self.current_confidence < 0.7:\n",
    "                return\n",
    "                \n",
    "            if current_action == 'curl':\n",
    "                self.count_curl_reps(image, landmarks)\n",
    "            elif current_action == 'squat':\n",
    "                self.count_squat_reps(image, landmarks)\n",
    "            elif current_action == 'plank':\n",
    "                self.count_plank_reps(image, landmarks)\n",
    "            elif current_action == 'pushup':\n",
    "                self.count_pushup_reps(image, landmarks)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in rep counting: {e}\")\n",
    "    \n",
    "    def count_curl_reps(self, image, landmarks):\n",
    "        \"\"\"Count bicep curl repetitions\"\"\"\n",
    "        # Get coordinates for bicep curl (use the more prominent arm)\n",
    "        try:\n",
    "            # Try left arm first\n",
    "            l_shoulder = self.get_coordinates(landmarks, 'left', 'shoulder')\n",
    "            l_elbow = self.get_coordinates(landmarks, 'left', 'elbow')\n",
    "            l_wrist = self.get_coordinates(landmarks, 'left', 'wrist')\n",
    "            \n",
    "            # Try right arm\n",
    "            r_shoulder = self.get_coordinates(landmarks, 'right', 'shoulder')\n",
    "            r_elbow = self.get_coordinates(landmarks, 'right', 'elbow')\n",
    "            r_wrist = self.get_coordinates(landmarks, 'right', 'wrist')\n",
    "            \n",
    "            # Calculate both angles\n",
    "            l_angle = self.calculate_angle(l_shoulder, l_elbow, l_wrist)\n",
    "            r_angle = self.calculate_angle(r_shoulder, r_elbow, r_wrist)\n",
    "            \n",
    "            # Use the arm with more movement (smaller angle indicates more curl)\n",
    "            if l_angle < r_angle:\n",
    "                angle = l_angle\n",
    "                elbow = l_elbow\n",
    "            else:\n",
    "                angle = r_angle\n",
    "                elbow = r_elbow\n",
    "            \n",
    "            # Curl detection logic\n",
    "            if angle < 50:  # Curled up position\n",
    "                self.curl_stage = \"up\"\n",
    "            elif angle > 120 and self.curl_stage == 'up':  # Extended position\n",
    "                self.curl_stage = \"down\"\n",
    "                self.curl_counter += 1\n",
    "            \n",
    "            # Visualize\n",
    "            self.viz_joint_angle(image, angle, elbow)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in curl counting: {e}\")\n",
    "    \n",
    "    def count_squat_reps(self, image, landmarks):\n",
    "        \"\"\"Count squat repetitions\"\"\"\n",
    "        try:\n",
    "            # Get coordinates for squat analysis\n",
    "            l_hip = self.get_coordinates(landmarks, 'left', 'hip')\n",
    "            l_knee = self.get_coordinates(landmarks, 'left', 'knee')\n",
    "            l_ankle = self.get_coordinates(landmarks, 'left', 'ankle')\n",
    "            \n",
    "            r_hip = self.get_coordinates(landmarks, 'right', 'hip')\n",
    "            r_knee = self.get_coordinates(landmarks, 'right', 'knee')\n",
    "            r_ankle = self.get_coordinates(landmarks, 'right', 'ankle')\n",
    "            \n",
    "            # Calculate knee angles\n",
    "            l_angle = self.calculate_angle(l_hip, l_knee, l_ankle)\n",
    "            r_angle = self.calculate_angle(r_hip, r_knee, r_ankle)\n",
    "            avg_angle = (l_angle + r_angle) / 2\n",
    "            \n",
    "            # Squat detection logic\n",
    "            if avg_angle < 100:  # Squatting down\n",
    "                self.squat_stage = \"down\"\n",
    "            elif avg_angle > 150 and self.squat_stage == 'down':  # Standing up\n",
    "                self.squat_stage = \"up\"\n",
    "                self.squat_counter += 1\n",
    "            \n",
    "            # Visualize\n",
    "            self.viz_joint_angle(image, l_angle, l_knee)\n",
    "            self.viz_joint_angle(image, r_angle, r_knee)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in squat counting: {e}\")\n",
    "    \n",
    "    def count_plank_reps(self, image, landmarks):\n",
    "        \"\"\"Count plank hold time\"\"\"\n",
    "        try:\n",
    "            # Get coordinates for plank analysis\n",
    "            l_shoulder = self.get_coordinates(landmarks, 'left', 'shoulder')\n",
    "            l_hip = self.get_coordinates(landmarks, 'left', 'hip')\n",
    "            l_knee = self.get_coordinates(landmarks, 'left', 'knee')\n",
    "            l_ankle = self.get_coordinates(landmarks, 'left', 'ankle')\n",
    "            \n",
    "            # Calculate body alignment\n",
    "            shoulder_hip_angle = self.calculate_angle(l_shoulder, l_hip, l_knee)\n",
    "            hip_knee_angle = self.calculate_angle(l_hip, l_knee, l_ankle)\n",
    "            \n",
    "            # Check if body is straight (good plank form)\n",
    "            body_straight = shoulder_hip_angle > 150 and hip_knee_angle > 150\n",
    "            \n",
    "            # Check if in horizontal position\n",
    "            horizontal = abs(l_shoulder[1] - l_hip[1]) < 0.15\n",
    "            \n",
    "            current_time = time.time()\n",
    "            \n",
    "            if body_straight and horizontal:\n",
    "                if self.plank_stage != \"holding\":\n",
    "                    self.plank_stage = \"holding\"\n",
    "                    self.plank_start_time = current_time\n",
    "            else:\n",
    "                if self.plank_stage == \"holding\":\n",
    "                    hold_duration = current_time - self.plank_start_time\n",
    "                    if hold_duration > 2:  # Minimum 2 seconds to count\n",
    "                        self.plank_counter += 1\n",
    "                    self.plank_stage = \"not_holding\"\n",
    "                    self.last_plank_end = current_time\n",
    "            \n",
    "            # Display timer\n",
    "            if self.plank_stage == \"holding\":\n",
    "                hold_time = current_time - self.plank_start_time\n",
    "                cv2.putText(image, f'Hold: {hold_time:.1f}s', (10, 400), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "            \n",
    "            # Visualize angles\n",
    "            self.viz_joint_angle(image, shoulder_hip_angle, l_hip)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in plank counting: {e}\")\n",
    "    \n",
    "    def count_pushup_reps(self, image, landmarks):\n",
    "        \"\"\"Count push-up repetitions\"\"\"\n",
    "        try:\n",
    "            # Get coordinates for push-up analysis\n",
    "            l_shoulder = self.get_coordinates(landmarks, 'left', 'shoulder')\n",
    "            l_elbow = self.get_coordinates(landmarks, 'left', 'elbow')\n",
    "            l_wrist = self.get_coordinates(landmarks, 'left', 'wrist')\n",
    "            \n",
    "            # Calculate elbow angle\n",
    "            angle = self.calculate_angle(l_shoulder, l_elbow, l_wrist)\n",
    "            \n",
    "            # Push-up detection logic\n",
    "            if angle < 70:  # Down position\n",
    "                self.pushup_stage = \"down\"\n",
    "            elif angle > 140 and self.pushup_stage == 'down':  # Up position\n",
    "                self.pushup_stage = \"up\"\n",
    "                self.pushup_counter += 1\n",
    "            \n",
    "            # Visualize\n",
    "            self.viz_joint_angle(image, angle, l_elbow)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in pushup counting: {e}\")\n",
    "    \n",
    "    def prob_viz(self, res, input_frame):\n",
    "        \"\"\"Visualize prediction probabilities\"\"\"\n",
    "        output_frame = input_frame.copy()\n",
    "        for num, prob in enumerate(res):\n",
    "            if num < len(self.actions):\n",
    "                cv2.rectangle(output_frame, (0, 60+num*40), (int(prob*100), 90+num*40), \n",
    "                            self.colors[num], -1)\n",
    "                cv2.putText(output_frame, self.actions[num], (0, 85+num*40), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        return output_frame\n",
    "    \n",
    "    def process_frame(self, frame, pose_model):\n",
    "        \"\"\"Process a single frame and return annotated frame\"\"\"\n",
    "        # Make detection\n",
    "        image, results = self.mediapipe_detection(frame, pose_model)\n",
    "        \n",
    "        # Draw landmarks\n",
    "        self.draw_landmarks(image, results)\n",
    "        \n",
    "        # Extract keypoints and make prediction\n",
    "        keypoints = self.extract_keypoints(results)\n",
    "        self.sequence.append(keypoints)\n",
    "        self.sequence = self.sequence[-self.sequence_length:]\n",
    "        \n",
    "        if len(self.sequence) == self.sequence_length:\n",
    "            # Make prediction\n",
    "            res = self.model.predict(np.expand_dims(self.sequence, axis=0), verbose=0)[0]\n",
    "            predicted_index = np.argmax(res)\n",
    "            self.current_confidence = np.max(res)\n",
    "            \n",
    "            # Update current action\n",
    "            if predicted_index < len(self.actions) and self.current_confidence > self.threshold:\n",
    "                self.current_action = self.actions[predicted_index]\n",
    "            else:\n",
    "                self.current_action = ''\n",
    "            \n",
    "            # Visualize probabilities\n",
    "            if len(res) >= len(self.actions):\n",
    "                image = self.prob_viz(res[:len(self.actions)], image)\n",
    "            \n",
    "            # Count reps\n",
    "            if results.pose_landmarks:\n",
    "                self.count_reps(image, self.current_action, results.pose_landmarks.landmark)\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def process_video(self, input_video_path, output_video_path=None):\n",
    "        \"\"\"Process a video file\"\"\"\n",
    "        print(f\"Processing video: {input_video_path}\")\n",
    "        \n",
    "        # Open video\n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {input_video_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "        width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        print(f\"Video properties: {width}x{height}, {fps} FPS, {total_frames} frames\")\n",
    "        \n",
    "        # Setup output video\n",
    "        out = None\n",
    "        if output_video_path:\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        # Reset counters\n",
    "        self.reset_counters()\n",
    "        \n",
    "        frame_count = 0\n",
    "        \n",
    "        # Process video\n",
    "        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                frame_count += 1\n",
    "                print(f\"Processing frame {frame_count}/{total_frames}\", end='\\r')\n",
    "                \n",
    "                # Process frame\n",
    "                processed_frame = self.process_frame(frame, pose)\n",
    "                \n",
    "                # Add counter display\n",
    "                cv2.putText(processed_frame, f'Curl: {self.curl_counter}', (10, 30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(processed_frame, f'Squat: {self.squat_counter}', (200, 30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(processed_frame, f'Plank: {self.plank_counter}', (420, 30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Display current action\n",
    "                action_text = f'Action: {self.current_action} ({self.current_confidence:.2f})'\n",
    "                cv2.putText(processed_frame, action_text, (10, height-20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Write to output video\n",
    "                if out is not None:\n",
    "                    out.write(processed_frame)\n",
    "                \n",
    "                # Display (optional - remove for faster processing)\n",
    "                cv2.imshow('Exercise Recognition', processed_frame)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        \n",
    "        # Cleanup\n",
    "        cap.release()\n",
    "        if out is not None:\n",
    "            out.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nProcessing complete!\")\n",
    "        print(f\"Final counts:\")\n",
    "        print(f\"  Curls: {self.curl_counter}\")\n",
    "        print(f\"  Squats: {self.squat_counter}\")\n",
    "        print(f\"  Planks: {self.plank_counter}\")\n",
    "        \n",
    "        if output_video_path:\n",
    "            print(f\"Output video saved to: {output_video_path}\")\n",
    "    \n",
    "    def process_webcam(self):\n",
    "        \"\"\"Process webcam feed in real-time\"\"\"\n",
    "        print(\"Starting webcam processing. Press 'q' to quit, 'r' to reset counters.\")\n",
    "        \n",
    "        cap = cv2.VideoCapture(0)\n",
    "        if not cap.isOpened():\n",
    "            print(\"Error: Could not open webcam\")\n",
    "            return\n",
    "        \n",
    "        self.reset_counters()\n",
    "        \n",
    "        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                \n",
    "                # Process frame\n",
    "                processed_frame = self.process_frame(frame, pose)\n",
    "                \n",
    "                # Add counter display\n",
    "                cv2.putText(processed_frame, f'Curl: {self.curl_counter}', (10, 30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(processed_frame, f'Squat: {self.squat_counter}', (200, 30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                cv2.putText(processed_frame, f'Plank: {self.plank_counter}', (420, 30), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Display current action\n",
    "                height, width = processed_frame.shape[:2]\n",
    "                action_text = f'Action: {self.current_action} ({self.current_confidence:.2f})'\n",
    "                cv2.putText(processed_frame, action_text, (10, height-20), \n",
    "                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                \n",
    "                # Display\n",
    "                cv2.imshow('Exercise Recognition - Webcam', processed_frame)\n",
    "                \n",
    "                key = cv2.waitKey(1) & 0xFF\n",
    "                if key == ord('q'):\n",
    "                    break\n",
    "                elif key == ord('r'):\n",
    "                    self.reset_counters()\n",
    "                    print(\"Counters reset!\")\n",
    "        \n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d40f7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run the exercise recognition\"\"\"\n",
    "    # CONFIGURATION - Update these paths and settings\n",
    "    MODEL_PATH = r\"C:\\Users\\pheno\\Downloads\\work\\main_model\\LSTM_Attention_128HUs_5ex_2nd.h5\"  # Path to your trained model\n",
    "    ACTIONS = ['curl', 'lunge', 'plank', 'situp', 'squat']  # Must match your training data order\n",
    "    \n",
    "    # Video processing\n",
    "    INPUT_VIDEO_PATH = r\"C:\\Users\\pheno\\Downloads\\work\\6632572755623995432.mp4\"\n",
    "    OUTPUT_VIDEO_PATH = \"output_exercise_recognition.mp4\"\n",
    "    \n",
    "    # Check if model exists\n",
    "    if not os.path.exists(MODEL_PATH):\n",
    "        print(f\"Error: Model file not found: {MODEL_PATH}\")\n",
    "        print(\"Please update MODEL_PATH with the correct path to your trained model.\")\n",
    "        return\n",
    "    \n",
    "    # Initialize recognizer\n",
    "    recognizer = ExerciseRecognizer(\n",
    "        model_path=MODEL_PATH,\n",
    "        actions=ACTIONS,\n",
    "        sequence_length=30,\n",
    "        confidence_threshold=0.5\n",
    "    )\n",
    "    \n",
    "    # Choose processing mode\n",
    "    print(\"Choose processing mode:\")\n",
    "    print(\"1. Process video file\")\n",
    "    print(\"2. Process webcam (real-time)\")\n",
    "    \n",
    "    choice = input(\"Enter choice (1 or 2): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        if os.path.exists(INPUT_VIDEO_PATH):\n",
    "            recognizer.process_video(INPUT_VIDEO_PATH, OUTPUT_VIDEO_PATH)\n",
    "        else:\n",
    "            print(f\"Error: Video file not found: {INPUT_VIDEO_PATH}\")\n",
    "    elif choice == \"2\":\n",
    "        recognizer.process_webcam()\n",
    "    else:\n",
    "        print(\"Invalid choice. Please run again and select 1 or 2.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd0baee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\pheno\\Downloads\\work\\main_model\\LSTM_Attention_128HUs_5ex_2nd.h5\n",
      "Model loaded successfully!\n",
      "Choose processing mode:\n",
      "1. Process video file\n",
      "2. Process webcam (real-time)\n",
      "Processing video: C:\\Users\\pheno\\Downloads\\work\\6632572755623995432.mp4\n",
      "Video properties: 1280x720, 29 FPS, 1348 frames\n",
      "Processing frame 1016/1348\n",
      "Processing complete!\n",
      "Final counts:\n",
      "  Curls: 0\n",
      "  Squats: 0\n",
      "  Planks: 0\n",
      "Output video saved to: output_exercise_recognition.mp4\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
